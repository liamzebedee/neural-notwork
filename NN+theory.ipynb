{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is based on perceptrons:\n",
    " - a perceptron takes a set of inputs $[x_0 ... x_n]$ and turns them into one ouput $y$\n",
    " \n",
    "![image.png](attachment:image.png)\n",
    "\n",
    " - Rosenblatt proposed a simple rule to compute the output. He introduced weights, $[w_0 ... w_n]$ real numbers expressing the importance of the respective inputs to the output\n",
    " - The neuron's output, 00 or 11, is determined by whether the weighted sum is less than or greater than some **threshold** value. This is called an **activation** function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Convolutional neural networks interpret images into high-level features.\n",
    "\n",
    " - Convolution\n",
    " - Non Linearity (ReLU)\n",
    " - Pooling or Sub Sampling\n",
    " - Classification (Fully Connected Layer)\n",
    " \n",
    " \n",
    "Convolution preserves the spatial relationship between pixels by learning image features using small squares of input data. It applies a convolution filter/kernel to a neighbourhood of pixels, and summarises it to one value. The matrix formed by sliding the filter over the image and computing the **dot product** is called the ‘Convolved Feature’ or ‘Activation Map’ or the ‘Feature Map‘. It is important to note that filters acts as feature detectors from the original input image. For a 3x3 pixel neighbourhood $a$ and a convolution filter $b$, the dot product is:\n",
    "\n",
    "${\\displaystyle \\mathbf {a} \\cdot \\mathbf {b} =\\sum _{i=1}^{n}a_{i}b_{i}=a_{1}b_{1}+a_{2}b_{2}+\\cdots +a_{n}b_{n}}$\n",
    "\n",
    "And visually:\n",
    "\n",
    "[https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&h=196](https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&h=196)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a convolution layer converts an image of pixels into a feature map $I\\rightarrow F$.\n",
    "\n",
    "Here are some resources:\n",
    " - [THE DEEP LEARNING BOOK](http://www.deeplearningbook.org/)\n",
    " - [dimensionality and 1x1 convs](https://stats.stackexchange.com/questions/194142/what-does-1x1-convolution-mean-in-a-neural-network)\n",
    " - [explaining convnets with intuition and diagrams](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)\n",
    " - [diff between neural and deep neural. explains connections, feedforward nets](https://stats.stackexchange.com/questions/182734/what-is-the-difference-between-a-neural-network-and-a-deep-neural-network)\n",
    " - [visual overview of convnets tools and concepts](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/)\n",
    " - [invariance in image recog](https://www.quora.com/How-is-a-convolutional-neural-network-able-to-learn-invariant-features)\n",
    " - \" a nonlinear system is a system in which the change of the output is not proportional to the change of the input.\"\n",
    " - NN's and [universal approx](https://en.wikipedia.org/wiki/Universal_approximation_theorem), [activation func](https://en.wikipedia.org/wiki/Activation_function), [perceptron](https://en.wikipedia.org/wiki/Perceptron)\n",
    " - [visually: why activations must be nonlinear](http://www.kdnuggets.com/2016/08/role-activation-function-neural-network.html)\n",
    " - [how neuronal connections work](http://swanintelligence.com/first-steps-with-neural-nets-in-keras.html)\n",
    " \n",
    "https://qph.ec.quoracdn.net/main-qimg-6718d32785c4b612b6182f52752f24f8?convert_to_webp=true![image.png](attachment:image.png)\n",
    "https://qph.ec.quoracdn.net/main-qimg-11fc98286eff9cd494a5b4614ba4a01d?convert_to_webp=true![image.png](attachment:image.png)\n",
    "http://swanintelligence.com/images/2016q1/neuron.png![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualising\n",
    "Keras conv filter https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "\n",
    "http://ankivil.com/visualizing-deep-neural-networks-classes-and-features/\n",
    "\n",
    "new variant of deconv approach https://arxiv.org/pdf/1412.6806v3.pdf\n",
    "\n",
    "example of deconv  https://datascience.stackexchange.com/questions/20469/keras-visualizing-the-output-of-an-intermediate-layer\n",
    "\n",
    "class activation maps for visualising where they pay attn https://jacobgil.github.io/deeplearning/class-activation-maps\n",
    "\n",
    "visualising in tensorflow simply https://medium.com/@awjuliani/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "\n",
    "visualising intermediate output https://datascience.stackexchange.com/questions/20469/keras-visualizing-the-output-of-an-intermediate-layer\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "https://github.com/fchollet/keras-resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Batch normalization\n",
    "[Batch normalization invention](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "\n",
    "We define Internal Covariate Shift as the change in the\n",
    "distribution of network activations due to the change in\n",
    "network parameters during training. To improve the training,\n",
    "we seek to reduce the internal covariate shift. By\n",
    "fixing the distribution of the layer inputs x as the training\n",
    "progresses, we expect to improve the training speed. It has\n",
    "been long known (LeCun et al., 1998b; Wiesler & Ney,\n",
    "2011) that the network training converges faster if its inputs\n",
    "are whitened – i.e., linearly transformed to have zero\n",
    "means and unit variances, and decorrelated.\n",
    "\n",
    "\n",
    "[SELU Paper](https://arxiv.org/pdf/1706.02515.pdf) [SELU](https://github.com/bioinf-jku/SNNs/blob/master/selu.py), [parameters](https://github.com/bioinf-jku/SNNs/blob/master/getSELUparameters.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "The insight is that you want your neural network to have uniform activations - that is, you want the activations of a layer to be in the same magnitude and not vary too much.\n",
    "\n",
    "The inputs to a neural network are random variables, and likewise the weights of the NN are the same.\n",
    "\n",
    "Scaled Exponential Linear Units do precisely this, but on an activation-level. They have properties which are inducing to zero mean and unit variance. \n",
    "\n",
    "When we refer to normalizing the activations, what we really are talking about is normalizing the mean and variance of the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
